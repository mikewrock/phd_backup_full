\chapter{Mobile Autonomous Shotcrete and Scanning System Overview}
\label{chap:overview}
\section{Chapter Overview}
\section{Hardware}
\subsection{Husky}
%https://www.clearpathrobotics.com/husky-unmanned-ground-vehicle-robot/
Clearpath's Husky Unmanned Ground Vehicle (Husky UGV) is the mobile base used for the proof of concept prototype. It is a four wheeled skid steer vehicle, capable of driving on uneven ground or loose gravel. It has a wheel diameter of 330 mm, and external dimensions of 990 mm $\times$ 670 mm $\times$ 390 mm. It's maximum payload is 75 kg and maximum speed is 1.0 m/s. Skid steer vehicles have notoriously unreliable odometry data which makes the Husky an excellent choice as a mobile base, since it creates a more realistic representation of the final product.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Pics/husky.jpg}
    \caption{Husky UGV \cite{huskypage}}
    \label{fig:husky}
\end{figure}
\subsection{Husky Peripherals}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pics/DSC0433.JPG}
    \caption{Husky With Peripherals Attached}
    \label{fig:peripherals}
\end{figure}
The Husky required a few modifications to support the additional hardware used. A top plate was machined to mount the manipulator, as well as a mounting bracket for the nodding head servo. A trailer hitch was installed and a trailer was built to allow the Husky to tow additional batteries, a generator, and the controller for the manipulator.\\
\subsection{DENSO VP6242}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Pics/denso.png}
    \caption{DENSO VP6242 Manipulator \cite{densopage}}
    \label{fig:sick}
\end{figure}
%https://www.denso-wave.com/en/robot/product/five-six/vp.html
The final product will likely use hydraulics to position the shotcreting and scanning end-effector. Since the payload and forces will require a high strength and rigidity manipulator, using electric motors unnecessarily expensive. Designing a manipulator for this task is outside the scope of this research, so a suitable analogue was chosen. The requirements of the manipulator is that it can position it's end-effector with 6 Degrees-of-Freedom like the final version, but does not require the same workspace, strength, or rigidity the final product would in order to accurately position the end-effector and apply shotcrete. The DENSO manipulator was chosen since it fulfils all the application requirements and was an available UOIT asset for use in this work. It has a maximum reach of 432 mm and a maximum payload of 2.5 kg.\\ 
\subsection{LMS101}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{Pics/sick.png}
    \caption{SICK LMS101 LiDAR \cite{sickpage}}
    \label{fig:sick}
\end{figure}
%https://www.sick.com/de/en/detection-and-ranging-solutions/2d-lidar-sensors/lms1xx/lms101-10000/p/p346868?ff_data=JmZmX2lkPXAzNDY4NjgmZmZfbWFzdGVySWQ9cDM0Njg2OCZmZl90aXRsZT1MTVMxMDEtMTAwMDAmZmZfcXVlcnk9JmZmX3Bvcz04JmZmX29yaWdQb3M9OCZmZl9wYWdlPTEmZmZfcGFnZVNpemU9OCZmZl9vcmlnUGFnZVNpemU9OCZmZl9zaW1pPTkzLjA=
The LMS101 is a LiDAR scanner manufactured by SICK. It has an aperture angle of 270$\degree$, angular resolution of 0.25$\degree$ at 25 Hz, and optimal range of 0.5 m - 20 m. SICK is a well know brand of LiDAR scanners, with lots of software drivers available for the various systems it works with. The ROS driver for this LiDAR does not natively support 0.25$\degree$ resolution, so it has been modified accordingly. It has a systematic error of $\pm$30 mm and statistical error	of 12 mm, though through testing it was found the LiDAR performs much better in the given test conditions. With and IP rating of IP65, it is suitable for indoor use but can be replaced with another model from the same family with equal performance but higher IP rating (up to IP67).\\
\subsection{Schunk Powercube PR70}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Pics/powercube.png}
    \caption{Schunk Powercube PR70 \cite{schunkpage}}
    \label{fig:schunk}
\end{figure}
The LiDAR used must be mounted on a nodding head to generate pointclouds. The Powercube PR70 made by Schunk was chosen for this task partly since it was already an asset of the UOIT MARS lab. The module has higher accuracy and payload than the application requires, but since it was an unused asset it was chosen for this application for practicality reasons. It has a nominal torque of 15 Nm, repeat accuracy of 0.03$\degree$, maximum angular velocity of 240$\degree$/s, and maximum acceleration of 960$\degree$/s$^2$. \\
\section{Software}
\label{sec:software}
All software integrated and developed for this research is intended for use within the ROS framework. Since ROS is an open source community with many packages available for use in research, it offers a wide selection of resources useful to this work.\\

Many of the tasks required for operation of the MASSS have already been developed by the ROS community. Hardware drivers, motion controllers, LiDAR scan to pointcloud assemblers, navigation, and mapping packages are already available through ROS. The following packages are necessary for the MASSS to function.\\
\subsection{RVIZ}
\label{sec:rviz}

Complete documentation on RVIZ can be found at \url{http://wiki.ros.org/rviz}\\

RVIZ is a powerful visualization tool developed for use with ROS. There is a large quantity of information that can be generated using ROS that is not easily interpreted without the use of an interactive graphical user interface. RVIZ allows users to view, interact with, interpret, and modify the data handled within ROS. RVIZ is an invaluable tool in mobile robotics; it can display a model of the robot, a map the robot has generated of its environment, the path it intends to follow, and display sensor data the robot acquires. The user can interact with RVIZ and send commands to the robot such as: position goals, movement commands, status changes, or selecting parts of the sensor data to be used in other software algorithms.\\

RVIZ is designed to be adaptable for whatever the operator needs. Custom tools and plugins are easily developed to make RVIZ helpful in the context it is used. In this work, a custom tool was implemented for selecting sections of the mine surface to be scanned or shotcreted. A custom plugin called the control panel was created to provide a user-friendly interface to command and control all relevant aspects of the MASSS.\\

RVIZ configurations can be saved to a file and loaded at launch when the robot control system is brought online. The configuration file for this work sets the RVIZ environment in a way that is practical for the operator, but includes options to reveal information useful for debugging and research. For example, under most circumstances the pointcloud representation of the mine surface should be shown but individual laser scans hidden. If the operator wanted to see the instantaneous view of the robot's environment represented as a laser scan, the topic's checkbox simply needs to be checked. Similarly, pointclouds are cropped to remove sections of the robot detected be the scanner can be visualized by enabling the appropriate display. When generating trajectories the surface path, surface normals, and end-effector path is shown, however the operator may only want some or none of the information displayed so they are all easily hidden or shown. This is all accomplished in the ``Displays'' panel of RVIZ. The configuration file subscribes RVIZ to all the available topics and automatically hides the topics containing information that does not need to be displayed.\\

\subsection{Husky}

Complete documentation of the Husky package can be found at \url{http://wiki.ros.org/Robots/Husky}\\

The Husky package is made by Clearpath Robotics to provide ROS functionality to their Husky Unmanned Ground Vehicle (UGV). The package consists of the following subpackages:

\begin{itemize}
    \item \node{husky_base}
    \item \node{husky_bringup}
    \item \node{husky_gazebo}
    \item \node{husky_viz}
    \item \node{husky_control}
    \item \node{husky_description}
    \item \node{husky_msgs}
    \item \node{husky_navigation}
\end{itemize}

\paragraph{husky\_base}

The \node{husky_base} package provides the low level communication between ROS and the robot. It contains all the necessary drivers to allow the robot to operate under ROS control.\\

\paragraph{husky\_bringup}

The \node{husky_bringup} package contains a number of scripts to that launch all the necessary packages (like \node{husky_base}) for the robot to function. Many applications for the Husky robot are intended to be turnkey, so the bringup package allows the designer to set what packages to launch when the robot boots up. Using the bringup package the robot can be configured to commence its control system as soon as it is powered on.\\

\paragraph{husky\_gazebo}

Gazebo is a simulation tool used in ROS. With a fully defined robot model, Gazebo can simulate the robot in a user defined environment. If an operator intends to test their algorithms on a Husky robot, but does not have access to a physical robot they can test their software on a simulated version of the Husky. Similarly, if the operator wants to test their robot in a scenario that may cause damage to the robot, or in an environment they are unable to create, they can use Gazebo to test their algorithms in simulation.\\

\paragraph{husky\_viz}

RVIZ configurations can be saved and loaded by ROS. The \node{husky_viz} package contains various configurations for RVIZ that optimize its configuration for use with the Husky.\\

\paragraph{husky\_control}

The package \node{husky_control} turns motion goals in to actual robot motion. The motion goals are published using ROS topics, and the \node{husky_control} package subscribes to these topics and moves the robot accordingly. The motion goals can be provided directly from the operator using an input device such as a joystick, or generated from autonomous navigation packages acting on a goal location provided by the operator. The source of the motion commands does not affect how the package functions, so it is able to receive motion command from a wide variety of sources as long as the commands are formatted using the appropriate ROS message type.\\ 

\paragraph{husky\_description}

In order to visualize the robot in the RVIZ environment, the robot requires a description. The robot description contains all the relevant information about the robot parts, which way they can move, what colour they are, and how to visually represent them. The description also contains the relevant physical characteristics to simulate the robot in Gazebo. The \node{husky_description} package uses the Unified Robot Description Format (URDF) to describe the model for the Husky UGV.\\

\paragraph{husky\_msgs}

To communicate with other packages, or within the Husky packages, custom messages for the Husky robot are used. The \node{husky_msgs} package contains these custom messages. An example of the HuskyStatus message can be found in Appendix \ref{app:huskystatus}

%\includecode[pythonstyle]{Code/HuskyStatus.msg}{HuskyStatus.msg}

\paragraph{husky\_navigation}

The \node{husky_navigation} package provides configurations and examples for using varous navigation packages with the Husky. It contains all the relevant information a navigation package requires to successfuly apply the navigation algorithm on the Husky. Parameters such as the robot's footprint size, how far away to stay from obstacles, what sort of behaviours to exhibit when encountering obstacles, and what sensor information is available are contained within the configuration files. Navigation packages configure their global and local planners with the files contained in the \node{husky_navigation} package. The configuration file for producing costmaps for use in navigation is shown in Appendix \ref{app:huskyconfig} .\\

The package contains launch files to use various navigation packages with the Husky robot as well as demos that will launch the required accompanying packages as well. Launch files for AMCL, Gmapping, Frontier Exploration, and Move Base packages are included, as well as an empty map for use when the robot is being simulated in Gazebo.\\ 

\subsection{Move Base}

Complete documentation of the Move Base package can be found at \url{http://wiki.ros.org/move_base}\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pics/overview_tf.png}
    \caption{Overview of the Move Base Package \cite{rosmovebase}}
    \label{fig:movebaseoverview}
\end{figure}

The \node{move_base} package takes high level commands such as a location goal and performs the necessary actions to drive the robot to that location. a graphical overview of the package is shown in Figure \ref{fig:movebaseoverview}. It divides the task among two planners, the global planner and the local planner. The global planner is responsible for creating the overall plan for the robot path. It uses a global costmap generated by the map server, which holds the map generated by the SLAM algorithm or loaded from file. The global costmap includes things like the inflation layer, which acts as a safety buffer by creating a region surrounding any obstacles within the map that the robot cannot enter. The local costmap is generated based on what the robot's sensors currently detect. If a person were to walk in front of the robot they would appear in the local costmap and the local planner would generate a path around the obstacle, attempting to continue along the path generated by the global planner. If a person or object is placed close enough to the robot such that the robot is now within the inflation layer of obstacle, it is considered stuck. Once stuck, the robot must execute recovery behaviours to become unstuck. Figure \ref{fig:recovery} shows what recovery behaviours \node{move_base} uses to free itself. First the robot deletes obstacles from the map that are further away than a user specified distance. If the robot is then free to move, it will continue its navigation. If the robot is still stuck, it will rotate on the spot to get an updated view of its surroundings. If it still cannot move it will clear the map of all obstacles that are not within the area it needs to rotate in place, and if still stuck will rotate once more to scan its environment for obstacles. Once the second clearing rotation is complete if it is still unable to move it will abort its current goal and release a message notifying the system it was unable to reach its target location.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pics/recovery_behaviors.png}
    \caption{Move Base Recovery Behaviours \cite{rosmovebase}}
    \label{fig:recovery}
\end{figure}

\subsection{Laser Assembler}


Complete documentation of the Laser Assembler package can be found at \url{http://wiki.ros.org/laser_assembler}\\

The \node{laser_assembler} package converts the stream of laserscan data to a pointcloud. When MASSS creates a pointcloud representation of it's surroundings, it tells \node{laser_assembler} package when to start and stop recording the laser scans generated by the LMS100 LiDAR scanner. The assembler will store all of the laserscans, along with the coordinate frame transformation from a fixed frame to the LiDAR frame at that moment. When the pointcloud scan is complete, \node{laser_assembler} is notified and produces a pointcloud in the coordinate frame requested by the user. Discussed further in Section \ref{sec:locsourceerror}, the parameter \var{ignore_laser_skew} is set to false so that each point in the laser scan is transformed using the current pose of the LiDAR rather than the whole scan at once.\\

\subsection{Hector SLAM}

Complete documentation of the Hector SLAM package can be found at \url{http://wiki.ros.org/hector_slam}\\

The \node{hector_slam} package contains the \node{hector_mapping} package used by the MASSS to perform SLAM. The two main SLAM packages available for use with ROS are Gmapping and Hector SLAM. Gmapping is a more popular algorithm, but requires odometry from the robot. Hector SLAM can perform SLAM without the need for odometry. While the MASSS does measure its odometry, it is intended for use on uneven rocky ground and odometry may not be reliable. For that reason, Hector SLAM was chosen as the SLAM algorithm for use on the MASSS. However, thanks to the modularity that ROS offers it is a simple task to utilize other SLAM algorithms like Gmapping on the MASSS.\\

\subsection{RQT Reconfigure}

Complete documentation of the RQT Reconfigure package can be found at \url{http://wiki.ros.org/rqt_reconfigure}\\

If a node has been configured with parameters that can change at runtime, \node{rqt_reconfigure} can be used to modify them. When the user launches the GUI, it will poll the ROS parameter server to determine which nodes have dynamically reconfigurable variables and what their values and acceptable ranges are. It then presents the user with a window that shows a list of nodes on the left. When a node is selected the configurable parameters are shown on the right, most often in the form of a slider bar. An example \node{rqt_reconfigure} GUI window can be seen in figure \ref{fig:dyngui2}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Pics/dyngui.png}
    \caption{\texttt{rqt\_reconfigure} GUI}
    \label{fig:dyngui2}
\end{figure}

\subsection{The MASSS ROS Package}
\label{sub:software}

A thorough discussion of the source code is provided in Chapter \ref{chap:code}, however an overview of the MASSS would be incomplete without mentioning the ROS package that provides its functionality. The complete code can be found in Appendix \ref{app:code}.\\ 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Pics/rviz_window.png}
    \caption{RVIZ User Interface}
    \label{fig:panel}
\end{figure}

The main interface between the user and the control system occurs within an RVIZ window. Along with the regular features of RVIZ, this software adds a panel and a tool to the RVIZ interface. The additional features can be seen in Figure \ref{fig:panel}. The code for the control panel is split between two files. For the system's current purpose it would be far less functional to have a standalone Graphical User Interface (GUI) and not use RVIZ for visualization therefore \node{control_dashboard} was designed as a plugin for RVIZ. As future work on this project continues, the need for RVIZ visualization may diminish, so the node was designed to make converting it to run without RVIZ a trivial task. Eventually, when this system is implemented in a mine, no graphical interface at all will be required on the machine itself. For that reason, the core functionality of the system lies in the \node{control_panel} node. The \node{control_dashboard} node simply relays the actions from the user interface to the \node{control_panel} node.\\

The \node{control_panel} node is the heart of the control system. It is responsible for calling the localization, trajectory generation, and thickness estimation services, as well as communication with the DENSO arm, PowerCube servo, and Husky UGV. Other MASSS-specific requirements such as cropping regions from the robots perception that are occupied by the robot itself, or  modifying trajectory points to fit within the DENSO arm's workspace are performed by the \node{control_panel} node. \\

The main contribution to the ROS community are the localization, trajectory generation, and thickness estimation services. These three services are intended to be as portable as possible so they can be useful in any robotics project, regardless of the system configuration. Should other researchers have a need for the service they provide, one simply needs to install the package and will be able to launch the desired service from the terminal or their own launch file. Unfortunately, due to this document's confidentiality the source code will not be made available, so the functionality of the compiled binaries are provided as-is.\\

\subsubsection{MASSS GUI}
\label{sub:gui}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{Pics/gui.pdf}
    \caption{MASSS GUI}
    \label{fig:thegui}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%FIX THIS FIGURE"CALCULATE THICKNESS"
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55555

The four tabs of the MASSS GUI control panel can be seen in Figure \ref{fig:thegui}. The main tab, called ``Operation'' is for use while the robot is operating. The red ``Stop'' button is a software activated emergency stop. The operation tab has a LiDAR scan button that commands the robot to perform a LiDAR scan using the nodding head and displays the resulting pointcloud in the RVIZ window. The ``Set Home'' button is pressed when the robot is in a location the operator intends to define as the origin. The home position is then used as the coordinate frame into which all other pointclouds are transformed in to. The ``Radiation Scan'' button generates a trajectory based on the current selection and performs the motions of a radiation scan. Clicking ``Apply Shotcrete'' generates a trajectory based on the current selection and performs the motions for shotcrete application. If no area is selected, the default region (defined with respect to the robot's centre) is used. ``Apply Continuously'' does the same thing but will drive forward and repeat the process until the operator stops it. Every time a pointcloud is acquired, it is saved to disk. The textbox allows the user to declare where they would like the pointclouds saved. The interface for recording localization markers is also present, and usage is discussed in Section \ref{sub:admin}.\\

Though the shotcrete thickness is automatically displayed after applying shotcrete, the user may want to perform additional thickness calculations with RVIZ data or previously saved data. Selecting an area of a pointcloud and clicking ``Set Initial Cloud'' and repeating the steps for the final cloud allows the operator to calculate the shotcrete thickness at a specified region by pressing ``Calculate Thickness''. If they simply want to calculate thickness from two previously saved files, the filenames and locations can be entered and the calculation is performed upon pressing ``Estimate Thickness''. The resulting data can be saved to disk using the ``Save'' button, or an analysis of the data can be printed to the terminal window by pressing ``Compare Results''.\\

The testing tab has many features useful in testing and developing new algorithms. Table \ref{tab:testing} explains each button's function.\\
\begin{table}[h!] 
\begin{tabular}{|L{0.2\textwidth}|L{0.8\textwidth}|}
\hline
\multicolumn{1}{|c|}{\textbf{Button}} & \multicolumn{1}{c|}{\textbf{Function}}\\ \hline
Arm Step & Allows user to step through manipulator trajectory one via point at a time\\ \hline
Reset & Reset the counter when stepping through trajectory via points\\ \hline
Marker Only & Display markers for via points instead of moving the manipulator\\ \hline
Set Home & Set home location\\ \hline
Generate Poses & Calculate required positions the robot must move to to apply shotcrete over selected area\\ \hline
Pose Step & Move to next location\\ \hline
Ctr & Counter for tracking current via point\\ \hline
Generate Trajectory & Generates a trajectory based on the current selection or default area, then saves to location entered in the ``Trajectory Save Location'' field\\ \hline
Execute Trajectory & Moves manipulator to simulate shotcrete application or radiation scan\\ \hline
Plot Path & Show the intended path the robot will travel to reach the desired location\\ \hline
Execute Path & Move robot to desired location\\ \hline
Show Nav Goal & Show robot's desired location\\ \hline
Estimate Thickness & Calculate thickness from previous two pointcloud scans\\ \hline
Nav Mode & Move LiDAR nodding head to a position for navigation (-1.57, other positions can be commanded by changing the value of the text box)\\ \hline
Localize & Localize the robot\\ \hline
Auto Crop & Automatically crop an area behind the robot that the trailer is likely to occupy from the pointcloud\\ \hline
Load Scan & Load a pointcloud from file and treat it as if it was a newly acquired scan\\ \hline
Load Trajectory & Load a trajectory from file (at the location specified under ``Trajectory Save Location'')\\ \hline
Reset Map & Reset the SLAM map\\ \hline
Scan & Perform a LiDAR scan\\ \hline

\end{tabular}
\caption{Testing Functions}
\label{tab:testing}
\end{table}

The final tab allows the user to manually command the manipulator. The user can initialize the arm, shut it down, or clear the errors. When sending a pose, the user can specify a target location and Point-to-Point motion (PTP), Continuous Path motion (CP), or use the Tool coordinate frame (T). Alternatively, the user can specify specific joint angles to move to. The user can also set the speed of the manipulator, or use the text box to send a WINCAPSIII formatted command. The current robot pose is displayed as well.\\