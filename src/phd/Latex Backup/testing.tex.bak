\chapter{Testing}
\label{chap:testing}

\section{Mock Mine}
\label{sec:mine}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/20170901_153356.jpg}
    \caption{MARS Lab Mock Mine (Picture to be replaced)}
    \label{fig:mockmine}
\end{figure}
Testing of the MASSS occurred in the Mechatronic and Robotic Systems (MARS) lab mock mine at UOIT. Figure \ref{fig:mockmine} shows a picture of the mock mine used for testing. The mine is 6m long, 3m wide, 1.5m tall, and the roof overhang is 1m. Since CAMECO's MacArthur River mine corridors are approximately 6m tall and 5-8m wide, the mock mine is considered a quarter scale representation. It is constructed from wood framing with foam surfaces and features. Figure \ref{fig:surfacefeature} shows an image of some of the surface features installed on the mine. The uneven surfaces and features are similar to what can be found in the MacArthur River mine. Due to practicality, the surface roughness is much smoother than the actual mine. The main difference with the lack of surface roughness is the normal estimation will be more accurate over smaller regions, but using a larger radius to calculate the surface normals will yield similar results. Currently the mock mine floor is plywood material, but it has been designed to support a gravel surface. While the gravel will more closely approximate an actual mine, the skid-steering of the robot significantly reduces the accuracy of the wheel odometry. Whether gravel or solid flooring is used, the wheel odometry must be regarded as unreliable. The MASSS relies on a number of other sensors and algorithms to estimate it's pose, and the software designed for the MASSS treats dead-reckoning as an unreliable source for localization.\\
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/20180305_154842.jpg}
    \caption{Mock Mine Surface Features (Picture to be replaced)}
    \label{fig:mockminefeat}
\end{figure}
\section{Test Scenarios}
\label{sec:scenario}
\subsection{Localization}
\label{see:loctestscenario}
The MASSS has a number of options for verifying its fiducial based location estimation algorithm. In order of increasing accuracy, they are:
\begin{itemize}
    \item Odometry
    \item Inertial Measurement
    \item Laser Scan Matching
    \item Simultaneous Localization and Mapping
    \item Adaptive Monte Carlo Localization
    \item OptiTrack Motion Capture
\end{itemize}

Odometry is measured using encoders mounted along the drive-train of the wheels. The main source of error in odometry readings is from wheel slippage. There is no way to detect if the wheels are slipping from the encoder readings alone. Inertial measurement units (IMU) use accelerometers, gyroscopes, and sometimes magnetometers to estimate relative motions of the unit. Accelerometers can estimate position by integrating the acceleration data twice to produce position data, but the effect of noise in the signal is amplified with each integration. Gyroscopes can measure angular acceleration, but the data and its accompanying noise must also be integrated twice to estimate orientation. A magnetometer can provide an absolute reference using the earths magnetic field, but must be calibrated for its environment and is very susceptible to electronic interference. Odometry and inertial measurement can be combined using data processing algorithms like the Kalman filter to produce dead-reckoning position estimates. The biggest problem when using dead-reckoning is the error can grow unbounded. Since there is no absolute reference, all position estimates are made relative to the previous readings. This means any error introduced in an estimate is added to all the errors of the previous estimates. Dead-reckoning is generally regarded as a low accuracy form of localization. Since the MASSS is a skid-steered vehicle, the odometry estimates are particularly unreliable. When the robot rotates the wheels skid across the surface in a way undetectable to the wheel encoders. Dead-reckoning estimation is most accurate when odometry and inertial measurement data are fused using a Kalman filter, however without an absolute measurement of the system it is impossible to provide a sufficiently accurate position estimate to use as a datum for comparison to the fiducial based location estimation algorithm.\\

Using the LIDAR scanner on the robot odometry can be estimated by matching laser scans and calculating the transformation between them. Laser scan matching does not lose accuracy due to wheel slippage since it is measuring distances to fixed surfaces in its environment, but it still only produces relative position estimates and as such its error can grow unbounded.\\

Simultaneous localization and mapping (SLAM) uses the LIDAR scanner to build a map of the environment and localize itself within the map. Since it uses fixed points of reference the error remains bounded. While SLAM algorithms employ adaptive monte carlo localization (AMCL) to localize within the generated map, it is possible to generate a highly accurate map prior to testing and only using AMCL for localization. Since a previously generated map can be post-processed to optimize it's accuracy, AMCL alone has been placed higher than SLAM for localization estimation accuracy.\\

The most accurate localization system available for this research is the OptiTrack motion capture system. The manufacturer states they system regularly achieves a positional error less than 0.3mm and rotational error below 0.05\degree. Since the motion capture system is an absolute measurement system any errors in previous measurements have no effect on the current position estimate. The OptiTrack system uses an array of cameras optimized for detecting infrared (IR) light. Each camera has IR LEDs to increase the amount of infrared light available for reflection. To use the tracking system, IR markers are placed on the robot to be tracked. The IR markers can be active or passive. Passive markers are coated with a material that is highly reflective to infrared light and can be easily seen by the cameras. Active markers contain a high powered IR LED that emits infrared light. Each active markers blinks at a specific frequency so that it can be uniquely identified by the tracking system. A single marker can only provide position information, so three markers are combined to form a trackable object. The trackable object is taught to the system using Motive's Tracking Tools software. Three or more markers are selected, and the distance between each of the markers form the parameters of the trackable object. Figure \ref{fig:trackable} shows one of OptiTrack's rigid body trackable objects, and Figure \ref{fig:motivetrackable} shows the three reflective markers selected within the motive software to form the trackable object. IR reflective markers are placed on three or more of the six arms of the rigid body. Using between three and six markers on the six arms of the rigid body 28 unique configurations can be assembled. If more than 28 objects need to be tracked at a time, alternate rigid body shapes or active markers are required.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/rgidi.jpg}
    \caption{Rigid Body Trackable Object With Three IR Markers Installed (pic to be replaced)}
    \label{fig:trackable}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/20180303_182327.jpg}
    \caption{OptiTrack Interface, Trackable Object (pic to be replaced)}
    \label{fig:motivetrackable}
\end{figure}

The OptiTrack cameras are placed in the robot environment such that the field of vision of the cameras cover as much of the workspace as possible, with as much overlap between the camera's field of view as possible. Once the cameras are placed in their fixed locations, the system can be calibrated. Calibration is achieved using the calibration wand shown in Figure \ref{fig:wand}. Having specific spacing between the collinear markers allows the tracking software to recognize the calibration wand when in view of a camera. The operator moves the wand to cover as much of each cameras field of view as possible. The software records the wand trajectory seen by each camera until the wanding process is complete. Once finished, the software computes each camera's location and image distortion in an iterative process. The longer this process runs for the more accurate the results are. Once the system determines each camera's location and image distortion the system is calibrated and ready for use. The origin and ground plane is set using the ground plane tool shown in Figure \ref{fig:groundplane}. It is placed level with the ground at a point the operator wishes to define as the origin for OptiTrack's coordinate system.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/20180303_164637.jpg}
    \caption{OptiTrack Ground Plane Tool (pic to be replaced)}
    \label{fig:groundplane}
\end{figure}

Since the OptiTrack motion capture system is the most accurate localization system available to track the location of the MASSS, it was chosen as the ground truth for the system. Ground truth is the positional data that is considered the most accurate value available. The accuracy of the MASSS localization system is determined by comparing the location estimates generated by the system to the ground truth values. The origin of the world coordinate frame generated by the MASSS is set by the user when they perform the initial localization scan so it may not be coincident with the coordinate frame of the OptiTrack system. To test the accuracy of the localization system the relative movement of the robot from it's initial location is compared to the pose change measured by the OptiTrack system.

\subsubsection{Localization Test}

The localization test was intended to verify the accuracy of the localization algorithm. The localization algorithm must detect the fiducial marker and determine its location. To do so it uses the LIDAR and nodding head to create a pointcloud of the environment. As previously discussed, dead-reckoning and map based techniques are not as accurate as the localization algorithm developed for this work is. This test confirms the algorithm is capable of providing localization estimates within $5cm$ of the ground truth location.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/20180303_174007.jpg}
    \caption{MASSS Trackable Rigid Body Marker}
    \label{fig:rigidbody}
\end{figure}

The OptiTrack motion capture system was used as ground truth for robot. The center of the fiducial marker was chosen to be coincident with the middle keypoint (See discussion in section \ref{sec:markercentre}). The fiducial marker was added to the OptiTrack motion capture list of trackable items, so the location in OptiTrack's coordinate frame can be recorded. The rigid body marker shown in Figure \ref{fig:rigidbody} mounted on the robot was the second trackable item added to OptiTrack. To calibrate the location of the trackable rigid body, the area of the robot normally cropped from the pointcloud was included in the scan. This scan detected the rigid body marker and its location with respect to the LIDAR was determined.\\

When the system performs a localization scan, it detects and reports the location of the fiducial marker. The transformation matrix from the robot base to the fiducial marker centre is defined as $^BT_M$. To verify the accuracy of the localization system the matrix $^BT_{M(Robot)}$ computed by the localization system is compared to the matrix $^BT_{M(OptiTrack)}$ computed by the OptiTrack measurements. $^BT_{M(OptiTrack)}$ is calculated as $^BT_R\times^OT_R^{-1}\times^OT_M$ using the following transformation matrices:
    
\begin{description}
    \item [$^OT_M$] Transform from OptiTrack's origin to the fiducial marker centre
    \item [$^OT_R$] Transform from OptiTrack's origin to the robot's rigid body marker
    \item [$^BT_R$] Transform from the robot base to the robot's rigid body marker
\end{description}

The test was performed at 10 different locations, indicated in Figure \ref{fig:scanlocations}. The locations were chosen so that the accuracy of the localization algorithm can be examined when scans are taken close to the fiducial marker, far from the marker, and on uneven ground. Two different sized fiducial markers were used, to examine the effect of marker size on the localization algorithm.\\


\subsubsection{Localization Sources of Error}
\label{sec:locsourceerror}

The first limiting factor in the accuracy of the localization estimate is the accuracy of the LIDAR scanner. The manufacturer states a systematic error of $\pm$30mm and statistical error of 12mm, however the accuracy decreases with larger distances and less reflected light. Boehler and Marbs provide a comprehensive analysis of the sources of error in laser measurement devices \cite{checkthebookmarsbar}. To determine the experimental accuracy of the LIDAR device repeatability testing was performed in the MARS lab mock mine. Accuracy testing is difficult to achieve, but can be performed by physically verifying distance measurements using a measuring tape or placing markers detectable by both the LIDAR and OptiTrack system and comparing the measured distances. Since these techniques introduce either human error or the measurement error discussed in section \ref{sec:markerdetectionaccuracy}, and algorithms for thickness estimation and localization require repeatability more than accuracy the focus was to determine the repeatability of the LIDAR scanner more so than the accuracy.\\

The LIDAR scanner is mounted on a servomotor acting as a nodding head. The servo is a SCHUNK PR70 rotary module having a 0.08\degree\hspace{0pt} repeatability. Since the encoder is relative there is no absolute accuracy specifications provided by the manufacturer. When the nodding head moves the LIDAR scanner, each individual laser scan is combined to form a point cloud. If the nodding head reports an incorrect position, the laser scan will be positioned incorrectly in the point cloud. Nodding head position error can come from the servo itself, or occur due to software latency. Since the operating system is not designed as a real-time operating system, the servo position data may get delayed when being sent to the laser scan assembler. Figure \ref{fig:headlag} shows a point cloud where the laser scan data had significant latency. To ensure latency is not an issue, all non essential processes are halted during the scanning process.\\
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/screenshot-1528748143.png}
    \caption{Pointcloud Data With Visible Gaps Dut To Latency}
    \label{fig:headlag}
\end{figure}
The mounting bracket for the laser scanner was designed to flex as little as possible. If the mounting bracket flexes or vibrates the calculated position of the LIDAR will differ from the true position. Since the laser scan assembler uses the forward displacement solution to calculate the nodding head position and cannot detect mechanical vibration or deformation, these sources of error can cause inaccuracy in the assembled point clouds. With this potential for error in mind the mounting bracket was designed to allow as little vibration and deformation as possible.\\

The LIDAR scanner measures a single point at a time, and uses an internal rotating mirror to sweep the laser in a horizontal line at a frequency of 25Hz. If the nodding head moves fast enough the position of the first point in the scan will be on a different plane than the last point in the scan. If the nodding head transmits the servo position at a higher frequency than the LIDAR scans, the laser scan assembler can transform each individual point measurement in to the fixed coordinate frame rather than the whole scan at once. This is a fairly CPU intensive process, and it was determined that a sufficiently slow slew rate could achieve accurate results. The maximum skew is defined as:

\begin{align}
    S_{max} = tan\left(\frac{\omega_H}{f_L}\right)
\end{align}

Where $S_{max}$ is the maximum skew angle from the first point in the scan to the last, $\omega_H$ is the nodding head angular velocity, and $f_L$ is the scanning frequency of the LIDAR.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/edgeveiling.png}
    \caption{Edge Veiling Effect}
    \label{fig:veiling}
\end{figure}

One of the most visible sources of error to the human eye is the edge veiling effect. It can be seen in Figure \ref{fig:veiling}. Since the laser beam is not a single point but a ray that spreads over distance, when it lands on an edge it is possible that the area of measurement may only partially lie on the surface. The remainder of the measurement area may lie on a further object, or beyond the measurement range of the scanner. The area that lands on the object's edge could be anywhere from a tiny fraction to a large majority of the measurement area. Depending on how much of the measurement area lies on the edge, how far the remaining measurement area is from the edge, and what the reflectivity of the surfaces are the measured point will be reported as somewhere between the edge and the surface beyond. The edge effect can be minimized using the Intensity Recovery Algorithm presented in \cite{bookbaredge} and \cite{theotherone}. The \node{laser_filters} package for ROS provides a ``ScanShadowsFilter'' that attempts to minimize the edge effect using the angle between the laser origin and two points. Given $P_1$ and $P_2$ with an origin $O$, the user can specify if $\angle OP_1P_2$ is beyond an acceptable range to remove the specified number of neighbouring data points. Since the fiducial marker keypoints used in this research are mounted such that they stand offset from the surface, it is possible the edge effect may affect the measured location of the keypoint.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/eddt.png}
    \caption{Two Sections of a Pointcloud Containing Keypoints. Left: Keypoint Near the Scanner. Right: Keypoint Far From Scanner}
    \label{fig:keypointresolution}
\end{figure}

Though the edge effect can lower the accuracy of the measured location of the fiducial marker keypoint, the resolution of the point cloud has a far greater impact. Figure \ref{fig:keypointresolution} shows two sections of a pointcloud containing marker keypoints. Since the resolution and reflected intensity decreases over distance, the marker keypoints further away from the scanner will have less data points and a lower intensity. As well, the edge effect occurs not just to discontinuous surfaces, but also to discontinuity in the reflectivity of the surface. At further distances from the scanner the laser point measurement area is larger and a significant enough portion may overlap the highly reflective surface of the marker keypoint to return a measured point with high enough intensity to be considered a portion of the marker keypoint. Figure \ref{fig:keypointinaccuracy} shows a portion of a pointcloud containing a keypoint, and indicates the possible locations the keypoint may be found. Since it is impossible to determine exactly where the keypoint is from that data, an averaging algorithm takes the mean location to be the assumed location of the keypoint. This introduces the largest source of error to the localization algorithm, affecting the estimate as discussed in section \ref{sec:figureitout} (comment: this is in the results section).\\
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/keypointerror.png}
    \caption{Two Potential Keypoint Locations (Shown in Black and White) With Error Highlighted in Red}
    \label{fig:keypointinaccuracy}
\end{figure}
The software portion of localization has a nearly insignificant loss of accuracy. Occasionally the operating system must perform mathematical operations using values with more digits than a variable can hold. For example, $\pi$ is infinite and non-repeating so it is impossible to perform any calculations with a truly accurate value of $\pi$. However, the computer can perform operations with sufficient accuracy that rounding errors are likely not a significant source of error.\\

\subsection{Trajectory Generation}

The testing of the trajectory generation algorithm is difficult to quantify. Throughout development visual confirmation was the main criteria for verifying successful trajectory generation. Simply said, if it was unsuccessful it would be immediately apparent. As the development process continued the algorithm improved to the point where it consistently generated suitable trajectories. The criteria for failure are:

\begin{itemize}
    \item No trajectory generated
    \item Trajectory point outside robot workspace
    \item Trajectory does not maintain optimal distance from surface
    \item Trajectory does cover the entire selected surface
    \item Trajectory path has undesirable overlap
\end{itemize}

As long as none of the failure criteria are met, the trajectory generation was considered successful. The testing strategy consists of generating trajectories from a variety of positions and orientations relative to the mine surface, as well as selecting different sections of the mine. Trajectories are generated at positions near and far from the walls, parallel and perpendicular to the surface, as well as wall sections, roof sections, and combined sections. Straight sections of the mine as well as curved sections are selected for trajectory generation. Section \ref{trajtesting} presents all the robot poses and mine sections for which trajectories have been generated during functionality testing and verification. In the following sections, the causes of the failure criteria are discussed.

\subsubsection{No trajectory generated}

This can happen when an empty pointcloud is sent to the trajectory generation service. If the user commands the robot to spray an empty area, no trajectory will be generated. Similarly, if the robot is not close enough to the mine surface and there exists no surfaces in the automatic shotcrete zone, or the automatic shotcrete zone is positioned such that it does not intersect with the mine surface the trajectory service will not return a trajectory. In any of these scenarios, it is entirely operator error that caused the failure. To avoid such failures autonomous functions and default values or properly trained operators can be used.\\

There is a verification in the \node{control_panel} node to ensure it does not execute an empty trajectory. The result of this type of failure would be no action on the robot, a desired behaviour.

\subsubsection{Trajectory Point Outside Robot Workspace}

The trajectory generation service was designed to be as modular as possible. None of the restrictions specific to the MASSS manipulator have been applied to the algorithm. The intention is that the service can be used in future work and on alternately configured systems. It is up to the user to ensure trajectory points are within the manipulator's workspace. In the MASSS, when executing a trajectory each point is verified to be within the robot workspace. If a trajectory point lies outside the robot workspace, the \node{control_panel} node will move the trajectory point to the nearest location within the manipulator's workspace. Since the MASSS will move trajectory points that are not within the robot's workspace, a trajectory point outside the workspace does not result in an error in trajectory execution. Additional causes of trajectory points lying outside the robot workspace is erroneous pointcloud data. If the laser scanner detects the manipulator when generating point clouds, the trajectory generation algorithm will attempt to generate a trajectory that includes those points as part of the surface. To avoid false readings of the environment, the manipulator is moved outside the visual range of the LIDAR when it is performing a surface scan, and the resulting data is cropped to remove any points that may result from the robot detecting itself.\\

Without relocating the trajectory points the manipulator will halt operation if commanded to move to a position outside it's workspace. Since the \cpnode\hspace{0pt} node should automatically move trajectory points if necessary, halting operation is the desired behaviour if a trajectory point still exists outside the manipulator's workspace.\\

\subsubsection{Trajectory Does Not Maintain Optimal Distance From Surface}

This scenario occurs frequently due to the limitations of the MASSS manipulator workspace. Since the workspace is small, trajectory points are often moved during execution. The only way to avoid this scenario is to navigate very close to the mine surface and apply shotcrete to small sections at a time. A robot designed to operate in an actual mine will require a manipulator with a sufficiently large workspace. Since the algorithms developed in this work can be tested and executed using the current workspace limitations, and this configuration of the MASSS is not designed to apply actual shotcrete, moving the trajectory points does not affect the testing and verification of the trajectory generation algorithm. When generating and displaying shotcrete trajectories optimal distance is always achieved, it is only when executing the trajectory on the MASSS that non-optimal distances from the mine surface may be seen.\\

Due to the robust algorithm developed the trajectory points will only be created at optimal distances from the mine surface. The only possibility of generating a misplaced trajectory point is if the PCL normal estimation function fails unexpectedly. This has never occurred during testing or development, and verifying the reliability of PCL algorithms is outside the scope of this work. During execution the trajectory points may be moved from outside the manipulator's workspace to within, which would result in sub-optimal distance from the mine surface. Being the intended action of the system, this scenario of sub-optimal spray distance is not considered a failure.\\

\subsubsection{Trajectory Does Cover The Entire Selected Surface}

The trajectory algorithm uses a subtractive approach to generating a shotcrete application trajectory. As it generates trajectory points it removes the original points from the pointcloud passed to it. Using this approach the entire surface will be covered by the generated trajectory.\\

If a section of the surface does not receive shotcrete, the thickness estimation will detect the area has insufficient shotcrete and the system can autonomously navigate to that area and reapply shotcrete. Without the additional verification of shotcrete application done by the MASSS, not covering the intended surface with shotcrete could be a significant failure resulting in risk to humans present. It is therefore recommended that the thickness estimation always be used to verify shotcrete application.\\

\subsubsection{Trajectory Path Has Undesirable Overlap}

A certain amount of overlap may be desirable when applying shotcrete. This can be configured using the \node{dynamic_reconfigure} node, ROS parameter server (through command line utilities), or changing the configuration file for the MASSS. An undesirable overlap occurs if the trajectory passes over a previously shotcreted area. Since the trajectory generation algorithm removes the points it has generated a spray trajectory for, it is unlikely the system can produce a trajectory that overlaps itself. During testing and development, the trajectory generation algorithm had never produced overlapping shotcrete spray paths.\\

Should the algorithm be modified in a way that results in undesirable overlapping spray patterns, additional shotcrete will be wasted. Overlapping layers of shotcrete does not reduce the safety provided by the shotcrete layer, and the material wastage is minimal. This failure is not critical to human safety or mine operation.\\

\subsection{Thickness Estimation}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Pics/controlpts.jpg}
    \caption{Control Points Marked on Mine and Simulated Shotcrete}
    \label{fig:my_label}
\end{figure}

To estimate the thickness of the applied shotcrete, an artificial shotcrete is applied to the surface of the mine. Magnets are used to ensure consistent placement of the artificial shotcrete. Control points are placed on the surface of the mine as well as the surface of the artificial shotcrete as shown in Figure \ref{fig:controlpts}. The control points are highly reflective of infrared light, so they are easy to distinguish from the surrounding area when examining Optitrack or LIDAR pointcloud data. The control points were placed normal to the artificial shotcrete surface. Using the control points, the point to mesh (P2M) thickness estimation can be verified, however the point to point (P2P) approach would require different placement to verify. Since the control points can only be used to verify the P2M approach, they are not used as the main criteria for verifying the accuracy of the thickness estimation.\\

Accuracy is verified through the use of control measurements. By taking scans before and after the artificial shotcrete is applied without moving the MASSS, thickness estimates can be generated without introducing the localization algorithm as a source of error. Though the thickness estimates using the P2P approach cannot be physically verified, the high repeatability of the LIDAR scans can be used to produce a reasonably accurate control measurement.\\

Thickness estimation is performed on the same section of artificial shotcrete from a variety of locations. Since the accuracy of the localization was tested separately the most accurate fiducial marker configuration was chosen. If using a similar configuration for the marker is not possible, the accuracy confidence can be lowered accordingly for the shotcrete thickness estimation. The robot was positioned at multiple locations, both near and far from the region of interest. At each location a LIDAR scan was taken with and without the artificial shotcrete applied. By performing a thickness estimation on the two scans taken from the same location, a control measurement can be recorded. This measurement can be used to compare a thickness estimate produced from two scans at different locations. \\

By manually registering multiple control measurements, they can be averaged to produce a more accurate estimate of the artificial shotcrete thickness. Minimizing distance and maximizing resolution yielded the most accurate representation of the artificial shotcrete thickness. Thickness estimates generated during testing were compared to multiple control measurements. First the control measurement is manually registered and compared to the most accurate estimate obtained to evaluate the accuracy of the control measurement. Second the control measurements taken at the same location where the test measurements were taken are compared to evaluate the accuracy of the thickness estimation when using the localization algorithm to register the two point clouds.\\

\subsubsection{Thickness Estimation Sources of Error}

Taking multiple scans at a single location for use as a control measurement removes the potential source of error from the localization algorithm, but factors like systematic measurement error, robot vibration or deformation, edge veiling, and other environmental conditions are still present. Any sources of error discussed in section \ref{sec:locsourceerror} not dependant on the software algorithm is also a source of error in thickness estimation.\\

While the edge effect can be identified and corrected when the edge is far from the background surface, in the case of small rock outcroppings creating many small edges the edge effect will appear to slightly smooth out the surface. The edge effect over small uneven surfaces will not have a large effect on the accuracy of thickness estimation. Since the edge effect effectively interpolates between the edge and the background, and proper application of shotcrete should yield a smooth surface, the main occurrence of this error would lie in the pre-shotcrete scans. However, since the edge effect would return a point further away from the surface toward the scanner's viewpoint than the true value, the error lands on the side of underestimating the thickness. As long as the thickness estimates are underestimated, safety assurances are maintained. Shotcrete usage and rebound calculations will be affected, but since they are not within the main scope of this work the current level of accuracy has been deemed sufficient.\\

Though the control measurements are not subject to errors introduced by localization, the actual thickness measurements are. If the robot moves during shotcrete application, it must use it's localization algorithm to register the two pointclouds to a common coordinate frame. Therefore, the thickness estimates cannot achieve higher accuracy than the localization system. If the accuracy of the localization is not sufficient, the system can be configured to take scans before each time it has to move, allowing it to achieve the accuracy of the control measurements.\\

The control measurements as well as the thickness estimates are subject to errors caused by the thickness estimation algorithm. As discussed in Sections \ref{sec:p2p} and \ref{sec:p2m}, the P2P and P2M methods of estimating thickness each have their own unique sources of error. Though preliminary research indicated P2P was the appropriate choice in this scenario, both methods were tested to evaluate which is the most accurate.\\