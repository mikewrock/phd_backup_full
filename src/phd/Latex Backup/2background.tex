\chapter{Background}
\label{chap:background}
\section{Literature Review}
\subsection{Autonomous Robotics in Mining}
Automated robotics in the mining industry began in 1967 when the first unmanned rail haulage system was used at the underground mine known as ``General Blumenthal'' in Germany. Nine years later the first remote controlled manipulator for use in the extraction of thin coal seams was demonstrated \cite{mani}. Over the next 20 years more than 160 papers were published on applications for robotic mining and currently they number in the thousands. With so much research done in this field, there are surprisingly few mines that fully exploit the potential of automated mining equipment.\\

The two biggest factors driving the adoption of autonomous robots in the mining industry are safety and efficiency. In a typical coal mine, workers are exposed to temperatures over 30$^\circ$C, humidity between 90\%-100\%, loud noise, dust, and potentially harmful toxins \cite{temp}. Safety is achieved by using a robot in place of a human, as well as using robots alongside people to monitor the conditions of the mine while workers are present. Robots developed by Green \cite{green} and Vogt \cite{vogt} have been deployed alongside workers to assess the safety conditions inside a gold mine after a blast has occurred and the workers are waiting for the noxious fumes to be ventilated. Using a thermal camera and a manipulator to test for loose rocks, Green, et al. developed a robot that would create safety forecasts. These daily safety forecasts resemble a weather forecast and identify potential hazards and estimate their risk \cite{greener}. The ``Numbat'' robot has been designed to navigate a mine after a collapse to asses safety conditions and perform reconnaissance before emergency personnel are deployed \cite{numbat2}.\\

Robots far outperform human operators when it comes to efficiency, being able to perform tasks with better accuracy and speed while not requiring breaks or rest. In a 2002 report on robotics in mining a comparison of the feasibility of certain tasks between a worker and a robotic machine was presented and can be seen in Table \ref{tab:table} \cite{table}.\\
%\begin{minipage}{\textwidth}
\begin{adjustbox}{max width=\textwidth}
\begin{center}
\begin{table}[ht!]
\caption[]{Miner or Robot: The Differing Possibilities \cite{table}}
\small
\hfill{}
\resizebox{6.5in}{!} {
\begin{tabular}{p{3in} p{2.5in} p{2in} p{3in}}
\toprule
Function & Miner & Robot\\
\midrule
mining in a dangerous environment & impossibly & simply\\
actions in narrow places & impossibly & simply\\
raise mining & impossibly & simply\\
transference of heavy loads & up 50 kg depends on individual & up 200 kg\\
decision-making in non-standard situations & hard & rapid\\
stable work without intervals & low & simply\\
speed of manipulation & simply & high\\
machinery maintenance & hard & impossibly\\
integration of information & limited & simply\\
information change & simply & rapid\\
assembly & simply & hard\\
intellectual recognition of technological situations & hard & impossibly for the present\\
machinery diagnostics & visual & simply\\
sensing & acoustic (50-12000 Hz) & visual in non-optic range, acoustic in non-audible range, ranging, exact measurement of speed, temperature, depth, forces, acceleration, slip, travel\\
\bottomrule
\end{tabular}
}
\hfill{}
\label{tab:table}
\end{table}
\end{center}
\end{adjustbox}
%\end{minipage}
One of the leaders in adoption of automated mining equipment is the coal industry. In Australia, 50\% of all longwall coal mining operations use automated shearing machinery \cite{auswall}. Mining companies are integrating robotics into their operations in two different ways, either autonomously or through teleoperation. Autonomous robots are able to perform tasks without any human supervision and they can work continuously without breaks as long as their power source does not deplete. Sometimes it is more desirable to have a human in the loop, but for various safety reasons, not near the actual location of interest. For these tasks teleoperated robots are ideal.\\

Autonomous robotic mining vehicles are able to navigate and avoid obstacles, make decisions based on their environment, and interact with their surroundings. They have an advantage over human operators because they never tire, make quick decisions, have the potential for greater environmental awareness, and are well suited for dangerous or hazardous tasks.\\

Autonomous vehicles have increased mining efficiency in some mines by 30\% \cite{30p}. There are many examples of autonomous vehicles used in mines to perform tasks like hauling ore \cite{haul}, drilling blast holes \cite{blast}, and excavating material \cite{excavate}. Automation is not limited by size, as there are extremely large automated machines like the 3,000-4,000 tonne electric walking dragline in \cite{large} or the stationary one weighing 3,500 tonnes from \cite{3500}. Often there are many autonomous vehicles in a mine operating simultaneously. Coordination of multiple vehicles requires robust transfer functions like the ones used in \cite{dump} to control dump trucks or discrete event control using Petri nets \cite{petri}. Strategies for automating multiple vehicles in a mine environment are discussed well in \cite{multi}.\\

Autonomous vehicles require a wide variety of sensors based on their specific applications. These sensors enable a robot to extract information during its task that humans may not have the ability to discern. In \cite{fuzzy}, fuzzy logic is used on sensor information from a force/torque sensor to extract ore. Even during drilling operations the type of rock being drilled can be determined \cite{drill}. Using sensors that can perceive features invisible to people, radiation hazards can be identified \cite{radio}, mining equipment can be guided to follow specific materials, and mines can be mapped with a variety of information. Longwall mining operations can automate the drill to follow a coal seam using infra-red sensors \cite{seam} and track their location with centimetre accuracy \cite{real}. Open pit mines can be examined and mapped at great detail using hyperspectral imaging that can determine ore composition \cite{spectral}.\\

\subsection{Sensor Technologies for Robotic Mining}

A popular saying goes ``In the land of the blind the one eyed man is king''. In many cases, a robot can be that one eyed man. Robots can be equipped with sensors that give them a far greater perception of their environment than human senses can achieve. Some mining robots have the ability to sense information about their surroundings like air toxicity, while others can perform simple tasks based on sensor information \cite{uground}.\\

In order to perform remotely operated, semi-autonomous, or autonomous mining tasks a robot is required to have some perception of its environment. The least automated machines, such as the remotely operated ``Numbat mine emergency response vehicle'' require a human operator to control the machine from a safe distance \cite{numbat}. In order to control the machine, the operator requires some knowledge of the machines position, status, and condition. Semi-autonomous tasks require more information about the environment to complete, and autonomous vehicles require a great deal of environmental information to perform their tasks safely and effectively. Robotic mining equipment can also increase safety by removing a human operator from the most hazardous areas of a mine.\\

Sensors are used to detect environmental information as well as internal information about the machine such as the positions and rates of change of its components. Sensors are crucial for robotic systems to operate and provide information such as the location of obstacles, the type and concentration of material encountered, and the position and orientation of the robot both with respect to its immediate surroundings as well as its position within the mine. There are many different types of sensors but most are used to perform one of two tasks, either localization or detecting and interacting with the environment. Without localization, the robot would not know its configuration or location within its environment. In order to navigate, the robot must have some idea of where it is and where it needs to go. While in transit, a robot must detect and avoid any obstacles in its path. When it reaches the desired location, the robot will often use the same sensors it used to detect obstacles to perform its required task, which often requires some interaction with its environment.\\

While some types of sensors can be used for both localization and interaction, the best way to discuss robotic sensors is to investigate how they are used to perform either of these two tasks.\\

\subsubsection{Localization}
\label{sec:local}

Localization is the process where the robotic vehicle estimates its pose (position and orientation) in its environment. Localization can be done either locally, which is a relative estimate to its previous location, or globally where it tracks its absolute position using some fixed frame of reference. The goal is to determine the position and orientation of the robot with reference to either a known location or the robot's starting point. When localizing globally the robot either starts with a map of its environment, or builds a map as it navigates in a process known as Simultaneous Localization and Mapping (\acrshort{slam}).\\

Some methods of localization use sensors that measure the distance travelled. By mounting encoders on the wheels of a vehicle the system can estimate where it is using dead reckoning. The problem with using encoders is they cannot account for wheel slippage and, as slippage occurs, the position error grows unbounded and can very quickly lead to an inaccurate position estimate. Madhavan, et al. decreased this error by using an Inertial Measurement Unit (\acrshort{imu}) along with encoders to make a more accurate estimate, but without some sort of reference to a map or absolute positioning device the error will still grow unbounded over time \cite{madhavan}. Banta and Rawson used a neural network to periodically correct an encoder based position estimate by recognizing landmarks within the mine using ultrasonic range finders \cite{fusion}, effectively limiting the error over time.\\

Ultrasonic sensors are used to measure distance between the sensor and an object using time-of-flight data. They are well suited for underground mines because of the rough surface of most obstacles \cite{proof}. Steele, Ganesh, and Kleve used ultrasonic sensors to navigate a scale model of a Load-Haul-Dump (LHD) machine in a mine-like environment \cite{ganesh}. Borthwick and Durrant-Whyte used an infrared range scanner and an Extended Kalman Filter (\acrshort{ekf}) to compare detected features with an a-priori map of the mine \cite{borth}. These features known as landmarks can be recognized using neural networks \cite{neural} and video cameras \cite{video} amongst other techniques. There are many algorithms for pose estimation using landmarks such as a feature based pose estimator \cite{feature}, iconic pose estimator \cite{iconic}, or a combination of the two \cite{both}, all of which use a Light Detection and Ranging (\acrshort{lidar}) sensor.\\

The first publication on the topic of \acrshort{slam} was in 1986 by Smith and Cheeseman \cite{smith1986,smith1990}. The topic was further developed by Leonard and Durrant-Whyte in 1991 \cite{len1991}. Since \acrshort{slam} can be achieved using rich sensor data like a 3D camera or with very sparse data like a single touch sensor, the methods of implementing \acrshort{slam} vary with the sensor data available. When sensor data is unique enough to form landmarks, topological maps can be formed where the connectivity of the landmarks is used rather than generating a grid style map. Using an Extended Kalman Filter (\acrshort{ekf}) to localize the robot with respect to landmarks, \acrshort{ekf} \acrshort{slam} \cite{ekfslam} was a popular choice until Fast\acrshort{slam} \cite{fastslam} was introduced followed by Fast\acrshort{slam}2 \cite{fastslam2} . The EFK \acrshort{slam} algorithm's computation time increases quadratically with the number of landmarks used, while Fast\acrshort{slam} earned its name because the algorithm scales logarithmically with landmark quantity. When landmarks cannot be relied upon, an array of discrete cells indicating occupancy is used to build the map in Occupancy Grid \acrshort{slam} \cite{graphslam}.\\

The task of localizing a robot in a previously constructed map or one that is currently being built is often achieved using particle filters. Monte Carlo Localization (\acrshort{mcl}) is a method of localizing a robot using particle filters \cite{mcl}. The system generates many estimates for its current location, each one called a particle. When the sensor data changes, each particle is updated and the expected sensor data is compared to the actual data for each particle. New particles are added near the particles that agree with the sensor data and conflicting particles are removed. Eventually, the system converges on the position estimate with the highest confidence. Since the particles must initially be evenly distributed across the map, the particle set can be quite large. As the particles converge, the need to occupy the entire map with particles becomes unnecessary. Using Kullback-Leibler Divergence (\acrshort{kld}) as an error estimate, the particles can be sampled in an adaptive manner \cite{kld,amcl}. \acrshort{kld} sampling for Adaptive Monte Carlo Localization (\acrshort{amcl}) has been shown to consistently converge faster than traditional \acrshort{mcl} \cite{kldproof}.\\

One of the more accurate but challenging and costly methods of localization employs the use of external devices to triangulate the vehicle's position. Shaffer and Stentz use a reflector on the vehicle to triangulate the position using a scanning laser system called Lasernet \cite{both}. Others mount computer recognizable images like barcodes that the vehicle can track its relative location to in order to determine the vehicle's absolute location \cite{barcode}. If a wireless network is already installed in the mine, robots can use the unique signal strength conditions that exist at each point in the mine to estimate their locations \cite{signal}. Rusu, et al. created a 2D a-priori node map using passive Radio Frequency Identification (\acrshort{rfid}) tags \cite{rfirusu}. The \acrshort{rfid} nodes located within the predefined node map allow the mobile robot to periodically correct its position estimate when detecting the unique signature of a \acrshort{rfid} node. The Mobile Automated Scanner Triangulateration (\acrshort{mast}) technique presented in Simela's work uses unique shapes specifically designed for detection by 2D laser scanners mounted in known locations within the mine to achieve the same results as the \acrshort{rfid} node map but with much greater accuracy \cite{simela}. While these methods are attractive because they can provide a reliable and accurate absolute position, they are often costly to implement since line-of-sight requirements means beacons must be mounted throughout the mine.\\

To improve the accuracy of any one type of sensor, an additional set of related sensor data can be fused with the original. Sensor fusion often leads to more accurate localization and obstacle avoidance. Localization can be done through the sensor fusion of video and laser range finder data as in \cite{vis1} and \cite{vis2}, using infra red and ultrasonic sensors in \cite{irsonic}, or using an entire sensor suite including laser scanners, rotary encoders, inclinometers, infra red, and attitude heading reference systems to perform \acrshort{mcl} as done in \cite{carlo}. The sensor fusion can be done through Kalman filters or more advance techniques like geometric optimization \cite{geom}.\\

\subsubsection{Interaction}
\label{sec:interact}

While localization is a feature required in many different types of mobile robot applications, the interaction between a mining robot and the mine is much more specialized. For that reason, and to protect trade secrets, there is much less work published on automated robotic mining. Based on a literature review, the mining industry that is adopting automation the fastest is coal mining. Various processes have been automated such as rock breaking \cite{breaker}, slope monitoring \cite{slope}, or continuous mining \cite{both}. Sahoo and Mazid developed an opto-tactile sensor that detects the coal-rock interface to automate a shearer machine in longwall mines \cite{opto}. Other techniques to detect the coal-rock interface include gamma ray coal thickness measurement systems \cite{gamma}, an induced vibration touch sensor \cite{vibe}, or Kelly's coal interface detector that uses pick force, rock vibration, and video \cite{kelly}.\\

Though extremely little research has been published in the field of automated uranium mining, there is a range of sensors available to detect the radiation emitted by uranium ore. By using multiple sensors, a directional gamma ray detector can be built \cite{chip}. Alternatively, direction can be determined through electron-gamma and gamma-gamma directional correlation \cite{eggg}. A device similar to the directional handheld gamma ray probe developed by Larsson and Djeffal may be implemented in a uranium mining robot to help it detect the location of the uranium ore \cite{dj}. There are no off-the-shelf components that are designed specifically to be used autonomously in a mine for the detection and location of uranium ore, but many of these detectors have the properties and functionality necessary. The next step in developing these sensors is to overcome the harsh working conditions of a robotic mining vehicle.\\

Surface scanning techniques are currently being researched in Cameco's Cigar Lake Mine where jet boring is used. In order to measure the size and shape of the cavity left behind after the jet boring process, a 3D surface scan is done. Ingram and Marshall researched three different scanner technologies in determining what functions best in the jet bore mine conditions \cite{ingjet}. Their greatest obstacle was the fog created by the freezing pipes used to keep the ground solid. Laser scanners offered high accuracy but performed poorly in fog. Ultrasonic sensors worked well in fog but did not provide as good accuracy. For their application a time-of-flight camera was chosen. The camera provided a 3D surface representation of the cavity and performed well in foggy conditions.\\

\subsection{Autonomous Shotcrete Robots}

Few autonomous shotcrete systems have developed primarily for research purposes, and, therefore, not as many papers are published on the design of the systems themselves. Shandong University in China was tasked with the kinematic analysis of an autonomous shotcrete robot and their findings can be found in \cite{kinshot}. In a paper published by Macmahon Mining Services located in Australia an autonomous shaft lining robot is presented \cite{sliner}. The shaft lining robot is lowered down a vertical shaft and applies shotcrete along the side walls. Using ultrasonic range finders the system estimates the thickness of the shotcrete layer by comparing pre- and post-shotcrete measurements.\\

Nabulsi et al. developed a full scale autonomous shotcrete robot in \cite{nabulsi}. They use a 3D \acrshort{lidar} scanner by AITEMIN called the LIDAC-16 to perform scans before and after shotcrete application. The sprayer trajectory is determined using the design profile of the tunnel rather than laser scans. They also use a mathematical model for shotcrete application to estimate shotcrete thickness in real-time based on the control inputs to the machine.\\

This work will improve on Nabulsi's work in a number of ways. Though they are taking before and after scans of the surface, they do not discuss using these scans to perform thickness estimation in \cite{nabulsi}, instead they use estimates based on a vehicle and shotcrete application model. While this provides real-time thickness estimates, a much more accurate estimate can be achieved using point cloud comparison methods. Doing so requires accurately aligning the before and after point cloud scans of the surface, a novel solution to which is presented herein. Shotcrete application can be done more accurately if the laser scans are used for trajectory generation as proposed in this work, yet Nabulsi's robot uses a predetermined path. In order to decrease dependence on human operators, this work will also introduce the functionality to autonomously improve the shotcrete layer if the detailed analysis of shotcrete thickness indicates it to be necessary.\\

\section{Patent Survey}

At the time of publication, there were no patents for autonomous shotcrete systems with the capabilities of the Mobile Autonomous Shotcreting and Scanning System (MASS) presented in this work. There are many patents for various types of shotcrete application systems \cite{cn1,cn2,cn3,cn4,cn5,cn6,cn7,cn8}, however, none have implemented autonomous application of the shotcrete. The closest patent to this technology with respect to shotcrete application is a paint spraying robot, but it requires far more input from the operator than the MASS and can only paint flat vertical walls \cite{paintpat}. There are few patents on robotic monitoring systems for mines, moreover, they do not specify measuring shotcrete thickness or discuss in detail what measurement capabilities they possess \cite{pat1,pat2}.\\

\section{ROS: The Robot Operating System}
\label{sec:ros}

\acrshort{ros} first emerged in 2007 from a company called Willow Garage as they adapted software originally developed in Stanford's Artificial Intelligence Laboratory. Development continued and in 2009 the first paper on \acrshort{ros} was published \cite{rosfirst}, \acrshort{ros}.org was launched, and the first tutorials were released. In 2010 the first official version \acrshort{ros} 1.0 was released followed by 11 more versions over the next 7 years as well as development of the next generation of \acrshort{ros}, called \acrshort{ros} 2. As of 2017, there are 9,395 unique packages available for users to download, implement, modify or use in any way allowed under the BSD license \cite{bsd}.\\

\acrshort{ros} is middleware designed specifically for robotics. It is a software framework that allows users to create software in a variety of programming languages such as \CC, Python, and Lisp. Software packages written for \acrshort{ros} can include nodes, message types, configuration files, and function libraries. The foundation of a \acrshort{ros} package is usually the nodes that are written for it however there are \acrshort{ros} packages available the do no include any software nodes. \acrshort{ros} nodes are software programs written in one of the supported languages for use within the \acrshort{ros} framework. Nodes are responsible for executing the given task. Nodes can communicate with each other regardless of what programming language they are written in. Multiple nodes can be run on a single machine or many machines can be used with one or more nodes running on each one.\\

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{Pics/simplenode.pdf}
    \caption{Simple \acrshort{ros} Usage}
    \label{fig:rosmessage}
\end{figure}

Nodes use the \acrshort{ros} framework to communicate with each other by publishing messages and subscribing to topics. Figure \ref{fig:rosmessage} shows a simple diagram of how two \acrshort{ros} nodes may communicate with each other. In this example, Node 1 is a `Publisher' and publishes a message to `Topic'. Node 2 is a `Subscriber' and subscribes to all messages published to `Topic'. Nodes perform the actions of sending and receiving messages when they `Spin'. When a publisher spins, any messages waiting to be published to a topic are published. When a subscriber spins it will look at all the topics it is subscribed to and execute a callback function using the data contained in the message from the topic if one is available. Whenever a node subscribes to a topic, a callback function must be defined. This function is executed when a \acrshort{ros} message is retrieved from a topic, usually processing the received message in some way. \acrshort{ros} messages contain data that can be divided into four categories: built-in datatypes, other message types, arrays, or headers. The built-in datatypes are commonly used datatypes like booleans, strings, floats, and integers of various precision. For example, when creating a message to describe a student, one might use a string for their name, an integer for their student ID, and a float for their GPA (or an array of floats to store grade points from each course they have taken). If one were to make a message to describe a classroom, they could include a string for the course name, an integer for the maximum capacity, and use an array of `student' messages to contain information of all the students in the class. A `header' is a message that is so commonly used it is treated as its own datatype. Headers are usually included in a message because they contain a unique ID, time-stamp, and frame-id. The frame-id is particularly useful in mobile robotics and helps organize all the possible frames of reference in a project by providing an identifier for each one.\\

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{Pics/complexnode.pdf}
    \caption{Advanced \acrshort{ros} Usage}
    \label{fig:roscomplex}
\end{figure}

Figure \ref{fig:roscomplex} shows a more complex utilization of the \acrshort{ros} framework. In this example Node 3 and Node 4 run on a separate machine, but \acrshort{ros} allows them all to communicate seamlessly as if they were on a single machine. As shown in Figure \ref{fig:roscomplex} nodes can publish to one or multiple topics (Node 1), subscribe to multiple topics (Node 4), or both publish and subscribe to one or more topics (Node 2). The topics are simply named channels for nodes to send and receive messages along.\\

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{Pics/services.pdf}
    \caption{\acrshort{ros} Node and Service Bidirectional Communication}
    \label{fig:rosservicelong}
\end{figure}

The \acrshort{ros} `Master' is a special node that enables the core functionality of \acrshort{ros}. It is never modified by the user and must always be run before executing \acrshort{ros} nodes. The master node allows nodes to find each other, exchange messages, and invoke services. Services are used when bidirectional communication between nodes is necessary (as shown in Figure \ref{fig:rosservicelong}). A service will advertise its name using the \acrshort{ros} master and nodes can invoke the service with request/response message pairs. When a service is called it is passed a request message and when it completes it returns a response message. Services are created just like nodes and can also publish and subscribe to topics as well as performing the service they advertise. Actions are very similar to services, but provide periodic updates as they are executing and can be preempted. An example usage for a service would be to generate a shotcrete spraying trajectory. A node would send a point cloud message representing the mine surface to the trajectory service and the service would send and arm trajectory message in response. An action could be used to execute the arm trajectory, where a node would send the arm trajectory as a goal, and the action would complete the motion. While the arm is moving, the action could provide feedback on the current position of the arm. At completion the action can provide a result, like a boolean for success, triggering another action to be performed. Should the user need to halt the spraying process or execute a different trajectory, the action can be preempted by sending a new goal.\\

The master node is also used to store information on the parameter server. The parameter server is a central location for \acrshort{ros} nodes to store and retrieve data. Data stored on the parameter server is usually values that do not change often. Nodes can place or retrieve data on the parameter server, which is typically used for various configuration settings. Any node can retrieve this information for their own use or modify it for use by other nodes. An example usage of the parameter server is to customize shotcrete spray patterns. Values like shotcrete flowrate, via-point distance, sprayer velocity, and surface offset can all be stored on the parameter server and loaded from disk at launch. When a shotcrete spraying trajectory is requested, the service can read the relevant specifications from the parameter server. A user can directly change the values on the parameter server, it can be loaded from a file, or modified by another node during runtime. A configuration file is used to save the parameters for future use when the robot is brought back online.\\

\acrshort{ros} can also record communication across topics using the \func{rosbag} function. A `rosbag' is a file with a .bag extension and holds all the messages sent across a given topic or topics. This tool is particularly useful for simulations based on existing data. A \acrshort{ros} bag file can be recorded on a laser scan topic as a robot drives around. The bag file can then be played back while a mapping algorithm is running to produce a map. Using a bag file, many different mapping algorithms can be developed and tested on previous experimental data without having to physically drive the robot every time.\\

Typical execution of a \acrshort{ros} package begins in the terminal window. The terminal window is a command line interface to the operating system. From there nodes can be run, services launched, parameter server values changed, and many other \acrshort{ros} specific features. A launch file has the extension .launch and provides a convenient way of launching multiple nodes and services at once as well as loading multiple sets of configuration parameters to the parameter server or to nodes directly. Using a launch file, all of the command line entries to launch and configure a \acrshort{ros} package can be executed using a singe command. The syntax of a launch file follows the Extensible Markup Language (\acrshort{xml}) formatting rules, which makes the document readable to both humans and machines. Launch files can be configured to launch when the computer system starts up, making it so an operator needs only to provide power to the system and it can begin running any software packages it has been programmed to launch.\\